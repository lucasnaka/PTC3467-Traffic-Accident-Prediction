{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:10.913150Z",
     "start_time": "2021-04-25T19:24:10.452008Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:14.081740Z",
     "start_time": "2021-04-25T19:24:10.918137Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "import re\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#do not show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import plotly for visualization\n",
    "import chart_studio.plotly as py\n",
    "import plotly.offline as pyoff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import sys\n",
    "from IPython.core.display import display, HTML\n",
    "sys.path.append('..')\n",
    "pyoff.init_notebook_mode()\n",
    "\n",
    "from pycaret.classification import *\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, classification_report, \\\n",
    "precision_score, recall_score, f1_score, fbeta_score, accuracy_score, matthews_corrcoef, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bokeh.resources import INLINE\n",
    "import bokeh.io\n",
    "from bokeh import *\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:14.271241Z",
     "start_time": "2021-04-25T19:24:14.108676Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# pd.set_option('plotting.backend', 'pandas_bokeh')\n",
    "bokeh.io.output_notebook(INLINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:14.672207Z",
     "start_time": "2021-04-25T19:24:14.474739Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Print rapido para dimensão do Dataframe\n",
    "def SZ(df):\n",
    "    print(f\"\"\"\n",
    "--- Dimensão ---\n",
    "Linhas:  {df.shape[0]}\n",
    "Colunas: {df.shape[1]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:14.798869Z",
     "start_time": "2021-04-25T19:24:14.681185Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Print rapido para dTypes do Dataframe\n",
    "def DT(df):\n",
    "    print(f\"\"\"\n",
    "--- DataTypes ---\n",
    "{df.dtypes}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:14.929480Z",
     "start_time": "2021-04-25T19:24:14.807241Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#print de distribuição de features numéricas\n",
    "def distFeaturesNumericas(df,num_columns):\n",
    "    for col in num_columns:\n",
    "        plt.figure(figsize = (30,5))\n",
    "        plt.hist([df[df['Target'] == 0][col],df[df['Target'] == 1][col]],bins = 30, color=['blue','pink'], label=['no fatal','yes fatal'])\n",
    "        plt.legend()\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:15.056956Z",
     "start_time": "2021-04-25T19:24:14.934284Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#print de distribuição de features categóricas\n",
    "def distFeaturesCategoricas(df,cat_columns):\n",
    "    for col in cat_columns:\n",
    "        N_0 = len(df[df['Target'] == 0][col].value_counts().index)\n",
    "        count_0 = df[df['Target'] == 0][col].value_counts().values\n",
    "\n",
    "        ind_0 = np.arange(N_0)  # the x locations for the groups\n",
    "        width = 0.35       # the width of the bars\n",
    "\n",
    "        fig = plt.figure(figsize = (30,5))\n",
    "        ax = fig.add_subplot(111)\n",
    "        rects1 = ax.bar(ind_0, count_0, width, color='blue')\n",
    "\n",
    "        N_1 = len(df[df['Target'] == 1][col].value_counts().index)\n",
    "        ind_1 = np.arange(N_1)  # the x locations for the groups\n",
    "        count_1 = df[df['Target'] == 1][col].value_counts().values\n",
    "        rects2 = ax.bar(ind_1+width, count_1, width, color='pink')\n",
    "\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title(col)\n",
    "        ax.set_xticks(ind_0 + width / 2)\n",
    "        ax.set_xticklabels(df[df['Target'] == 0][col].value_counts().index)\n",
    "\n",
    "        ax.legend( (rects1[0], rects2[0]), ('not fatal', 'yes fatal') )\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:15.184391Z",
     "start_time": "2021-04-25T19:24:15.061976Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#print de distribuição de features categóricas\n",
    "def distFeaturesCategoricas(df,cat_columns):\n",
    "    for col in cat_columns:\n",
    "        N_0 = len(df[df['Target'] == 0][col].value_counts().index)\n",
    "        count_0 = df[df['Target'] == 0][col].value_counts().values\n",
    "\n",
    "        ind_0 = np.arange(N_0)  # the x locations for the groups\n",
    "        width = 0.35       # the width of the bars\n",
    "\n",
    "        fig = plt.figure(figsize = (30,5))\n",
    "        ax = fig.add_subplot(111)\n",
    "        rects1 = ax.bar(ind_0, count_0, width, color='blue')\n",
    "\n",
    "        N_1 = len(df[df['contem_vitTargetima_fatal'] == 1][col].value_counts().index)\n",
    "        ind_1 = np.arange(N_1)  # the x locations for the groups\n",
    "        count_1 = df[df['Target'] == 1][col].value_counts().values\n",
    "        rects2 = ax.bar(ind_1+width, count_1, width, color='pink')\n",
    "\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title(col)\n",
    "        ax.set_xticks(ind_0 + width / 2)\n",
    "        ax.set_xticklabels(df[df['Target'] == 0][col].value_counts().index)\n",
    "\n",
    "        ax.legend( (rects1[0], rects2[0]), ('not fatal', 'yes fatal') )\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:15.311335Z",
     "start_time": "2021-04-25T19:24:15.189269Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Get last saved version\n",
    "dataset_versions_path = '../data/processed'\n",
    "dataset_versions_list = [f for f in listdir(dataset_versions_path) if isfile(join(dataset_versions_path, f))]\n",
    "\n",
    "for file_name in dataset_versions_list:\n",
    "    if 'dataset_' in file_name:\n",
    "        last_train_dataset = file_name\n",
    "        \n",
    "last_version = [int(s) for s in re.findall(r'\\d+',last_train_dataset)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:15.585450Z",
     "start_time": "2021-04-25T19:24:15.316324Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(f'../data/processed/dataset_train_v{last_version}.parquet')\n",
    "df_validation = pd.read_parquet(f'../data/processed/dataset_validation_v{last_version}.parquet')\n",
    "df_test = pd.read_parquet(f'../data/processed/dataset_test_v{last_version}.parquet')\n",
    "print(f'Version loaded: v{last_version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:15.759106Z",
     "start_time": "2021-04-25T19:24:15.627375Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "cluster = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:15.932775Z",
     "start_time": "2021-04-25T19:24:15.768013Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train['cluster_coords']==cluster,:]\n",
    "df_validation = df_validation.loc[df_validation['cluster_coords']==cluster,:]\n",
    "df_test = df_test.loc[df_test['cluster_coords']==cluster,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:16.074400Z",
     "start_time": "2021-04-25T19:24:15.937767Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "SZ(df_train)\n",
    "DT(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Classification via PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the documentation in [Pycaret Classification](https://pycaret.org/classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:16.229216Z",
     "start_time": "2021-04-25T19:24:16.090360Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# ignore_columns = ['id', 'cluster_coords']\n",
    "ignore_columns = ['cluster_coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:16.356397Z",
     "start_time": "2021-04-25T19:24:16.234197Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "#       'dia_semana'\n",
    "#     , 'uf'\n",
    "#     , 'fase_dia'\n",
    "#     , 'sentido_via'\n",
    "#     , 'condicao_metereologica'\n",
    "#     , 'tipo_pista'\n",
    "#     , 'tracado_via'\n",
    "#     , 'uso_solo'\n",
    "#     , 'em_janela_feriado'\n",
    "#     #, 'cluster_coords'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:16.484330Z",
     "start_time": "2021-04-25T19:24:16.361514Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# num_columns = [\n",
    "#     'risco'\n",
    "#     , 'risco_morte'\n",
    "#     , 'pessoas'\n",
    "# #     , 'coordenada_x'\n",
    "# #     , 'coordenada_y'\n",
    "# #     , 'coordenada_z'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:16.640436Z",
     "start_time": "2021-04-25T19:24:16.489840Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:24:36.292311Z",
     "start_time": "2021-04-25T19:24:16.650410Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp_reg = setup(data=df_train,\n",
    "                test_data=df_validation,\n",
    "                target = 'Target',\n",
    "#                 numeric_features = num_columns,\n",
    "                categorical_features = cat_columns,\n",
    "                ignore_features = ignore_columns,\n",
    "                normalize=False,\n",
    "                pca=False,\n",
    "                create_clusters=False,\n",
    "                fix_imbalance=False,\n",
    "                #fix_imbalance_method = smote_nc,\n",
    "                data_split_stratify=False,\n",
    "                ignore_low_variance=False,\n",
    "                transformation=False,\n",
    "                #train_size=0.8,\n",
    "                combine_rare_levels=False,\n",
    "                fold=folds,\n",
    "                rare_level_threshold=0.10,\n",
    "                feature_ratio=False,\n",
    "                feature_interaction=False,\n",
    "                feature_selection=True,\n",
    "                feature_selection_method='boruta',\n",
    "                remove_multicollinearity=False,\n",
    "                remove_perfect_collinearity=False,\n",
    "                remove_outliers=False,\n",
    "                polynomial_features=False,\n",
    "                session_id=123,\n",
    "#                 log_experiment=True,\n",
    "#                 experiment_name='Predict Fatal Victim smotek5',\n",
    "#                 log_plots=True,\n",
    "#                 log_profile=False,\n",
    "#                 log_data=True,\n",
    "                silent=True,\n",
    "                verbose=True,\n",
    "                profile=False,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T13:34:02.132256Z",
     "start_time": "2020-12-02T13:34:01.846296Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing all models to evaluate performance is the recommended starting point for modeling once the setup is completed (unless you exactly know what kind of model you need, which is often not the case). This function trains all models in the model library and scores them using stratified cross validation for metric evaluation. The output prints a score grid that shows average Accuracy, Recall, Precision, F1, Kappa, and MCC accross the folds (10 by default) along with training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T01:26:10.687093Z",
     "start_time": "2021-04-23T01:23:03.473127Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "best = compare_models(sort='AUC',\n",
    "                      include=['catboost', 'xgboost', 'lightgbm'],\n",
    "                      fold=folds,\n",
    "                      n_select=3,\n",
    "                      turbo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The AUC metric is not available for Multiclass classification however the column will still be shown with zero values to maintain consistency between the Binary Classification and Multiclass Classification display grids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_model` is the most granular function in PyCaret and is often the foundation behind most of the PyCaret functionalities. As the name suggests this function trains and evaluates a model using cross validation that can be set with fold parameter. The output prints a score grid that shows Accuracy, Recall, Precision, F1, Kappa and MCC by fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:20.740923Z",
     "start_time": "2021-04-25T19:24:41.021303Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_cat = create_model('catboost', fold=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T01:27:16.863419Z",
     "start_time": "2021-04-20T01:27:08.410029Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_lightgbm = create_model('lightgbm', fold=folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a model is created using the create_model() function it uses the default hyperparameters to train the model. In order to tune hyperparameters, the tune_model() function is used. This function automatically tunes the hyperparameters of a model using Random Grid Search on a pre-defined search space. The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC by fold for the best model. To use the custom search grid, you can pass custom_grid parameter in the tune_model function (see 9.2 KNN tuning below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T20:30:48.144683Z",
     "start_time": "2020-12-07T20:05:31.494906Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "param_test ={'learning_rate' : [1e-5, 1e-3, 1e-2, 5e-1, 1e-1],\n",
    "             'n_estimators' : sp_randint(10, 1000),\n",
    "             'num_leaves': sp_randint(6, 75), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "tuned_model_lgbm = tune_model(model_lgbm, n_iter=100, custom_grid=param_test, optimize='AUC', choose_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tune_model()` function is a random grid search of hyperparameters over a pre-defined search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T22:04:46.278788Z",
     "start_time": "2020-12-07T20:30:48.146366Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuned_model_cat = tune_model(model_cat, n_iter=100, optimize='AUC', choose_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T22:53:18.433945Z",
     "start_time": "2020-12-07T22:04:46.280753Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "bagging_tuned_model_cat = ensemble_model(tuned_model_cat, fold=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T22:54:56.577136Z",
     "start_time": "2020-12-07T22:53:18.435906Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "bagging_tuned_model_lgbm = ensemble_model(tuned_model_lgbm, fold=folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T23:43:03.995526Z",
     "start_time": "2020-12-07T22:54:56.579121Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "stacked_models = stack_models(estimator_list = best[1:], meta_model = best[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before model finalization, the `plot_model()` function can be used to analyze the performance across different aspects such as AUC, confusion_matrix, decision boundary etc. This function takes a trained model object and returns a plot based on the test / hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:21.601625Z",
     "start_time": "2021-04-25T19:26:20.759873Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model_cat, 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:22.164120Z",
     "start_time": "2021-04-25T19:26:21.618578Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model_cat, 'class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:22.619901Z",
     "start_time": "2021-04-25T19:26:22.177084Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model(model_cat, 'feature_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-09T23:57:38.819975Z",
     "start_time": "2021-03-09T23:57:38.201666Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model_cat, 'calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-09T23:57:39.210933Z",
     "start_time": "2021-03-09T23:57:38.821970Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "pred_lightgbm = predict_model(model_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:05:23.869933Z",
     "start_time": "2021-03-09T23:57:39.212925Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "calibrated_model = calibrate_model(model_cat, fold=folds, method='isotonic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:05:24.572378Z",
     "start_time": "2021-03-10T00:05:23.872926Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_model(calibrated_model, 'calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:05:25.023172Z",
     "start_time": "2021-03-10T00:05:24.573375Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "pred_lightgbm = predict_model(calibrated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:13:38.709997Z",
     "start_time": "2021-03-10T00:05:25.024169Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "calibrated_model2 = calibrate_model(model_cat, fold=folds, method='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:13:39.398249Z",
     "start_time": "2021-03-10T00:13:38.713985Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_model(calibrated_model2, 'calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:13:39.854033Z",
     "start_time": "2021-03-10T00:13:39.401241Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "pred_lightgbm = predict_model(calibrated_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:13:43.705008Z",
     "start_time": "2021-03-10T00:13:42.927268Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model_lightgbm, 'calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:13:44.235588Z",
     "start_time": "2021-03-10T00:13:43.707001Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "predict_model(model_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:13:56.029272Z",
     "start_time": "2021-03-10T00:13:44.237583Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "calibrated_lightgbm = calibrate_model(model_lightgbm, fold=folds, method='isotonic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:13:57.101200Z",
     "start_time": "2021-03-10T00:13:56.031268Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_model(calibrated_lightgbm, 'calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:13:57.962897Z",
     "start_time": "2021-03-10T00:13:57.102199Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "predict_model(calibrated_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:15:12.645722Z",
     "start_time": "2021-03-10T00:15:07.215940Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "calibrated_lightgbm2 = calibrate_model(model_lightgbm, fold=folds, method='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:15:13.393513Z",
     "start_time": "2021-03-10T00:15:12.646645Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_model(calibrated_lightgbm2, 'calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T00:15:13.977846Z",
     "start_time": "2021-03-10T00:15:13.395404Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "predict_model(calibrated_lightgbm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T18:35:24.069551Z",
     "start_time": "2021-03-06T18:35:23.539940Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product # Biblioteca para achar valores mais próximos entre 2 arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:22.808395Z",
     "start_time": "2021-04-25T19:26:22.633862Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def optimize_threshold(df_predicted, verbose=False):\n",
    "    f1_score_array, precision_score_array, recall_score_array = [], [], []\n",
    "    thresholds_list = np.linspace(0,1,101)\n",
    "\n",
    "    with tqdm(total = len(thresholds_list)) as pbar:\n",
    "        for threshold in thresholds_list:\n",
    "            df_predicted['Target'] = df_predicted['Target'].astype(int)\n",
    "            df_predicted['y_pred'] = df_predicted.apply(lambda x: 1 if x['Score'] >= threshold else 0, axis=1)\n",
    "\n",
    "            f1_score_array.append(f1_score(df_predicted['Target'], df_predicted['y_pred']))\n",
    "    #         precision_score_array.append(precision_score(df_predicted['Target'], df_predicted['y_pred']))\n",
    "    #         recall_score_array.append(recall_score(df_predicted['Target'], df_predicted['y_pred']))\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "        best_threshold_f1 = thresholds_list[np.argmax(f1_score_array)]\n",
    "        if verbose:\n",
    "            plt.plot(thresholds_list, f1_score_array)\n",
    "            plt.axvline(x=best_threshold_f1)\n",
    "            plt.title(f'Best threshold based on F1-Score = {best_threshold_f1}')\n",
    "            plt.show()\n",
    "\n",
    "    #     #Find closest values between precision and recall arrays\n",
    "    #     closest_pr = sorted(product(precision_score_array, recall_score_array), key=lambda t: abs(t[0]-t[1]))[0]\n",
    "\n",
    "    #     # Get index of closest values between precision and recall arrays\n",
    "    #     indices_precision = [i for i, x in enumerate(precision_score_array) if x == closest_pr[0]]\n",
    "    #     indices_recall = [i for i, x in enumerate(precision_score_array) if x == closest_pr[1]]\n",
    "    #     indice_best_threshold = list(set(indices_precision) & set(indices_recall))[0]\n",
    "\n",
    "    #     plt.plot(thresholds_list, precision_score_array)\n",
    "    #     plt.plot(thresholds_list, recall_score_array)\n",
    "    #     plt.axvline(x=thresholds_list[indice_best_threshold])\n",
    "    #     plt.title(f'Best threshold based on Precision x Recall = {thresholds_list[indice_best_threshold]}')\n",
    "    #     plt.show()\n",
    "    \n",
    "    return best_threshold_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:23.193364Z",
     "start_time": "2021-04-25T19:26:22.820362Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_predicted = predict_model(model_cat, probability_threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:51.136952Z",
     "start_time": "2021-04-25T19:26:23.203337Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "best_threshold = optimize_threshold(df_predicted, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:51.658523Z",
     "start_time": "2021-04-25T19:26:51.163880Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_predicted['y_pred'] = df_predicted.apply(lambda x: 1 if x['Score'] >= best_threshold else 0, axis=1).astype(int)\n",
    "df_predicted['Target'] = df_predicted['Target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:51.955033Z",
     "start_time": "2021-04-25T19:26:51.658523Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print('AUC:', roc_auc_score(df_predicted['Target'], df_predicted['Score']))\n",
    "print('Accuracy:', accuracy_score(df_predicted['Target'], df_predicted['y_pred']))\n",
    "print('Precision:', precision_score(df_predicted['Target'], df_predicted['y_pred']))\n",
    "print('Recall:', recall_score(df_predicted['Target'], df_predicted['y_pred']))\n",
    "print('F1-Score:', f1_score(df_predicted['Target'], df_predicted['y_pred']))\n",
    "print(classification_report(df_predicted['Target'], df_predicted['y_pred']))\n",
    "print(confusion_matrix(df_predicted['Target'], df_predicted['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:26:52.419772Z",
     "start_time": "2021-04-25T19:26:51.957615Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_predicted_2020 = predict_model(model_cat, probability_threshold=0.0, data=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:27:14.273138Z",
     "start_time": "2021-04-25T19:26:52.429746Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "best_threshold = optimize_threshold(df_predicted_2020, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:27:14.684433Z",
     "start_time": "2021-04-25T19:27:14.295048Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_predicted_2020['y_pred'] = df_predicted_2020.apply(lambda x: 1 if x['Score'] >= best_threshold else 0, axis=1).astype(int)\n",
    "df_predicted_2020['Target'] = df_predicted_2020['Target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T19:27:14.968711Z",
     "start_time": "2021-04-25T19:27:14.697406Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print('AUC:', roc_auc_score(df_predicted_2020['Target'], df_predicted_2020['Score']))\n",
    "print('Accuracy:', accuracy_score(df_predicted_2020['Target'], df_predicted_2020['y_pred']))\n",
    "print('Precision:', precision_score(df_predicted_2020['Target'], df_predicted_2020['y_pred']))\n",
    "print('Recall:', recall_score(df_predicted_2020['Target'], df_predicted_2020['y_pred']))\n",
    "print('F1-Score:', f1_score(df_predicted_2020['Target'], df_predicted_2020['y_pred']))\n",
    "print(classification_report(df_predicted_2020['Target'], df_predicted_2020['y_pred']))\n",
    "print(confusion_matrix(df_predicted_2020['Target'], df_predicted_2020['y_pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T11:07:44.643671Z",
     "start_time": "2021-02-02T11:07:44.227153Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_metrics(df, y_true, y_pred, average='macro', labels = [0, 1]):\n",
    "    df['y_true'] = df[y_true].astype(str)\n",
    "    df['y_pred'] = df[y_pred].astype(str)\n",
    "    \n",
    "    print(classification_report(df['y_true'], df['y_pred'], labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:50:08.349205Z",
     "start_time": "2020-11-24T19:50:07.723566Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# tuned_model_xgb_final = finalize_model(tuned_model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T11:07:46.046259Z",
     "start_time": "2021-02-02T11:07:44.647660Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = get_config(\"X_train\").reset_index()[['index']].merge(new_df.drop(ignore_columns, axis=1).reset_index(), how='left', on='index')\n",
    "del df_train['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T11:08:07.698952Z",
     "start_time": "2021-02-02T11:07:46.046259Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_train = predict_model(model_rf, data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T11:08:11.499108Z",
     "start_time": "2021-02-02T11:08:07.698952Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_test = predict_model(model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T11:08:41.227516Z",
     "start_time": "2021-02-02T11:08:11.499108Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print('------------------- Train Metrics -------------------')\n",
    "generate_metrics(model_predicted_train, 'Target', 'Label')\n",
    "\n",
    "print('------------------- Test Metrics -------------------')\n",
    "generate_metrics(model_predicted_test, 'Target', 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:51:15.972335Z",
     "start_time": "2020-11-24T19:51:01.469561Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_train = predict_model(model_lgbm, data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:51:18.051853Z",
     "start_time": "2020-11-24T19:51:15.974959Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_test = predict_model(model_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:51:39.439050Z",
     "start_time": "2020-11-24T19:51:18.051853Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print('------------------- Train Metrics -------------------')\n",
    "generate_metrics(model_predicted_train, 'Target', 'Label')\n",
    "\n",
    "print('------------------- Test Metrics -------------------')\n",
    "generate_metrics(model_predicted_test, 'Target', 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:51:51.721544Z",
     "start_time": "2020-11-24T19:51:39.441047Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_train = predict_model(model_cat, data=df_train, probability_threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:51:53.009934Z",
     "start_time": "2020-11-24T19:51:51.721544Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_test = predict_model(model_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T19:52:17.245450Z",
     "start_time": "2020-11-24T19:51:53.011396Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print('------------------- Train Metrics -------------------')\n",
    "generate_metrics(model_predicted_train, 'Target', 'Label')\n",
    "\n",
    "print('------------------- Test Metrics -------------------')\n",
    "generate_metrics(model_predicted_test, 'Target', 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T18:24:44.330347Z",
     "start_time": "2020-10-30T18:24:42.901851Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_data = [\n",
    "    go.Histogram(\n",
    "        x = tx_data['TARGET'],\n",
    "        orientation='v',\n",
    "        name='Segmentos'\n",
    "    )\n",
    "]\n",
    "\n",
    "plot_layout = go.Layout(\n",
    "        width=700,\n",
    "        height=300\n",
    "    )\n",
    "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "pyoff.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "r = evaluate_all(lgbm_final_pred_test['y_true'], lgbm_final_pred_test['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "lgbm_final_pred_test.to_csv(\"../data/processed/Predict Revenue Purchase_LGBM_129.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T11:14:01.565573Z",
     "start_time": "2021-02-02T11:09:27.818732Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_rf_finalized = finalize_model(model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T11:14:03.850555Z",
     "start_time": "2021-02-02T11:14:01.569563Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "save_model(model_rf, \"../models/model_rf_02_02_2021\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T13:51:32.140058Z",
     "start_time": "2021-01-24T13:51:18.710882Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_et = predict_model(model_et)\n",
    "\n",
    "print('------------------- et -------------------')\n",
    "generate_metrics(model_predicted_et, 'Target', 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_2020 = pd.read_parquet('../data/processed/datasetSMOTENC2020.parquet')\n",
    "df_2020['data_inversa'] = pd.to_datetime(df_2020['data_inversa'])\n",
    "df_2020.head()\n",
    "# df_2020 = df_2020.drop(['data_inversa','risco_morte','em_janela_feriado'], axis=1)\n",
    "\n",
    "SZ(new_df_resampled)\n",
    "DT(new_df_resampled)\n",
    "SZ(df_2020)\n",
    "DT(df_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# df_train = get_config(\"X_train\").reset_index()[['index']].merge(new_df_resampled.drop(ignore_columns, axis=1).reset_index(), how='left', on='index')\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T16:16:08.544142Z",
     "start_time": "2021-03-06T16:16:08.320735Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#z_score2020 = stats.zscore(df_2020.drop(['id'], axis=1).drop(['Target'], axis=1).select_dtypes(include=[np.number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T16:16:08.805440Z",
     "start_time": "2021-03-06T16:16:08.554113Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#abs_z_scores2020 = np.abs(z_score2020)\n",
    "#filtered_entries2020 = (abs_z_scores2020 < 3).all(axis=1)\n",
    "#sum(filtered_entries2020)#\n",
    "#new_df2020 = df_2020[filtered_entries2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#df_2020['Target'].value_counts().plot(kind='bar', title='Count (target)');\n",
    "#df_2020_0 = df_2020[df_2020['Target'] == 0]\n",
    "#df_2020_1 = df_2020[df_2020['Target'] == 1]\n",
    "#print(df_2020_0.shape[0]/(df_2020_0.shape[0]+df_2020_1.shape[0]))\n",
    "#print(df_2020_1.shape[0]/(df_2020_0.shape[0]+df_2020_1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#model_predicted_cat = predict_model(model_cat, data=df_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#print('------------------- cat -------------------')\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#confusion_matrix(model_predicted_cat['Target'], model_predicted_cat['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#new_df_2020_0 = new_df2020[new_df2020['Target'] == 0]\n",
    "#new_df_2020_1 = new_df2020[new_df2020['Target'] == 1]\n",
    "#print(new_df_2020_0.shape[0]/(new_df_2020_0.shape[0]+new_df_2020_1.shape[0]))\n",
    "#print(new_df_2020_1.shape[0]/(new_df_2020_0.shape[0]+new_df_2020_1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#model_predicted_cat2 = predict_model(model_cat, data=new_df2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#print('------------------- cat 2-------------------')\n",
    "#confusion_matrix(model_predicted_cat2['Target'], model_predicted_cat2['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#model_predicted_dt = predict_model(model_dt, data=df_2020)\n",
    "\n",
    "#print('------------------- dt -------------------')\n",
    "#confusion_matrix(model_predicted_dt['Target'], model_predicted_dt['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = get_config(\"X_train\").reset_index()[['index']].merge(new_df_resampled.drop(ignore_columns, axis=1).reset_index(), how='left', on='index')\n",
    "df_test = get_config(\"X_test\").reset_index()[['index']].merge(new_df_resampled.drop(ignore_columns, axis=1).reset_index(), how='left', on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_cat_train = predict_model(model_cat, data=df_train)\n",
    "confusion_matrix(model_predicted_cat_train['Target'], model_predicted_cat_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_cat_test = predict_model(model_cat, data=new_df_split_test)\n",
    "confusion_matrix(model_predicted_cat_test['Target'], model_predicted_cat_test['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_cat = predict_model(model_cat, data=df_2020)\n",
    "confusion_matrix(model_predicted_cat['Target'], model_predicted_cat['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_tunedcat = predict_model(tuned_model_cat, data=df_2020)\n",
    "confusion_matrix(model_predicted_tunedcat['Target'], model_predicted_tunedcat['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_tunedcat_test = predict_model(tuned_model_cat, data=new_df_split_test)\n",
    "confusion_matrix(model_predicted_tunedcat_test['Target'], model_predicted_tunedcat_test['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_dt_train = predict_model(model_dt, data=df_train)\n",
    "confusion_matrix(model_predicted_dt_train['Target'], model_predicted_dt_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "model_predicted_dt_test = predict_model(model_dt, data=new_df_split_test)\n",
    "confusion_matrix(model_predicted_dt_test['Target'], model_predicted_dt_test['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_predicted_dt = predict_model(model_dt, data=df_2020)\n",
    "confusion_matrix(model_predicted_dt['Target'], model_predicted_dt['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print('------------------- dt test-------------------')\n",
    "print(\"Accuracy : \",accuracy_score(model_predicted_dt_test['Target'], model_predicted_dt_test['Label']))\n",
    "#print()\n",
    "print(\"Recall : \",recall_score(model_predicted_dt_test['Target'], model_predicted_dt_test['Label']))\n",
    "print(\"Precision : \",precision_score(model_predicted_dt_test['Target'], model_predicted_dt_test['Label']))\n",
    "\n",
    "\n",
    "print('------------------- cat test-------------------')\n",
    "print(\"Accuracy : \",accuracy_score(model_predicted_cat_test['Target'], model_predicted_cat_test['Label']))\n",
    "print(\"Recall : \",recall_score(model_predicted_cat_test['Target'], model_predicted_cat_test['Label']))\n",
    "print(\"Precision : \",precision_score(model_predicted_cat_test['Target'], model_predicted_cat_test['Label']))\n",
    "\n",
    "\n",
    "print('------------------- dt 2020-------------------')\n",
    "print(\"Accuracy : \",accuracy_score(model_predicted_dt['Target'], model_predicted_dt['Label']))\n",
    "print(\"Recall : \",recall_score(model_predicted_dt['Target'], model_predicted_dt['Label']))\n",
    "print(\"Precision : \",precision_score(model_predicted_dt['Target'], model_predicted_dt['Label']))\n",
    "\n",
    "\n",
    "print('------------------- cat 2020-------------------')\n",
    "print(\"Accuracy : \",accuracy_score(model_predicted_cat['Target'], model_predicted_cat['Label']))\n",
    "print(\"Recall : \",recall_score(model_predicted_cat['Target'], model_predicted_cat['Label']))\n",
    "print(\"Precision : \",precision_score(model_predicted_cat['Target'], model_predicted_cat['Label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "print('------------------- cat 2020-------------------')\n",
    "print(\"Accuracy : \",accuracy_score(model_predicted_cat['Target'], model_predicted_cat['Label']))\n",
    "print(\"Recall : \",recall_score(model_predicted_cat['Target'], model_predicted_cat['Label']))\n",
    "print(\"Precision : \",precision_score(model_predicted_cat['Target'], model_predicted_cat['Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_train_split = get_config(\"X_train\").reset_index()[['index']].merge(new_df_resampled.drop(ignore_columns, axis=1).reset_index(), how='left', on='index')\n",
    "model_predicted_cat_train_split = predict_model(model_cat, data=df_train_split)\n",
    "print('------------------- cat train split-------------------')\n",
    "print(\"Accuracy : \",accuracy_score(model_predicted_cat_train_split['Target'], model_predicted_cat_train_split['Label']))\n",
    "print(\"Recall : \",recall_score(model_predicted_cat_train_split['Target'], model_predicted_cat_train_split['Label']))\n",
    "print(\"Precision : \",precision_score(model_predicted_cat_train_split['Target'], model_predicted_cat_train_split['Label']))\n",
    "\n",
    "model_predicted_cat_split = predict_model(model_cat, data=new_df_split_test)\n",
    "print('------------------- cat test split-------------------')\n",
    "print(\"Accuracy : \",accuracy_score(model_predicted_cat_split['Target'], model_predicted_cat_split['Label']))\n",
    "print(\"Recall : \",recall_score(model_predicted_cat_split['Target'], model_predicted_cat_split['Label']))\n",
    "print(\"Precision : \",precision_score(model_predicted_cat_split['Target'], model_predicted_cat_split['Label']))\n",
    "\n",
    "\n",
    "model_predicted_cat = predict_model(model_cat, data=df_2020)\n",
    "print('------------------- cat 2020-------------------')\n",
    "print(\"Accuracy : \",accuracy_score(model_predicted_cat['Target'], model_predicted_cat['Label']))\n",
    "print(\"Recall : \",recall_score(model_predicted_cat['Target'], model_predicted_cat['Label']))\n",
    "print(\"Precision : \",precision_score(model_predicted_cat['Target'], model_predicted_cat['Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_test = get_config(\"X_test\").reset_index()[['index']].merge(new_df_split_test.drop(ignore_columns, axis=1).reset_index(), how='left', on='index')\n",
    "df_test[df_test['index']==26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "new_df_split_test.sort_index().iloc[[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df_test.equals(new_df_split_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "train_models"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "173.7px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
